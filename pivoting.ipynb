{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # بارگذاری فایل\n",
    "# df = pd.read_csv('gen_brg_vib.csv')\n",
    "\n",
    "# # لیست AssetIDهای مورد نظر\n",
    "# asset_ids = [9362, 9363, 9364, 9365, 9366, 9367, 9371, 9372]\n",
    "\n",
    "# # لیست ستون‌های مورد نظر\n",
    "# columns = ['Value', 'RecordTime', 'RecordDate', 'DateTime', 'TimeStamp']\n",
    "\n",
    "# # لیست برای نگهداری دیتافریم‌های جداگانه\n",
    "# dfs = []\n",
    "\n",
    "# # پردازش هر AssetID به‌صورت جداگانه\n",
    "# for aid in asset_ids:\n",
    "#     df_aid = df[df['AssetID'] == aid][columns].copy()\n",
    "#     df_aid.columns = [f\"{col}_{aid}\" for col in columns]\n",
    "#     dfs.append(df_aid.reset_index(drop=True))\n",
    "\n",
    "# # ترکیب همه دیتافریم‌ها در محور افقی\n",
    "# df_final = pd.concat(dfs, axis=1)\n",
    "\n",
    "# # ذخیره فایل نهایی\n",
    "# df_final.to_csv('flattened_by_assetid.csv', index=False)\n",
    "\n",
    "# print(\"✅ فایل نهایی با ستون‌های جداگانه برای هر AssetID ذخیره شد: flattened_by_assetid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # بارگذاری فایل خروجی قبلی\n",
    "# df = pd.read_csv('flattened_by_assetid.csv')\n",
    "\n",
    "# # لیست AssetIDها\n",
    "# asset_ids = [9362, 9363, 9364, 9365, 9366, 9367, 9371, 9372]\n",
    "\n",
    "# # لیست برای نگهداری ردیف‌های نهایی\n",
    "# final_rows = []\n",
    "\n",
    "# # تعداد ردیف‌ها\n",
    "# n = len(df)\n",
    "\n",
    "# # پیمایش ردیف‌ها\n",
    "# for i in range(n):\n",
    "#     row = df.iloc[i]\n",
    "#     base_values = {}\n",
    "#     valid = True\n",
    "\n",
    "#     for aid in asset_ids:\n",
    "#         base_ts = row[f'TimeStamp_{aid}']\n",
    "#         if pd.isna(base_ts):\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # تبدیل به عدد برای محاسبه اختلاف\n",
    "#         try:\n",
    "#             base_ts = float(base_ts)\n",
    "#         except:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # جستجوی نزدیک‌ترین TimeStamp در 5 ردیف بعدی\n",
    "#         min_diff = float('inf')\n",
    "#         closest_value = None\n",
    "\n",
    "#         for j in range(i+1, min(i+6, n)):\n",
    "#             next_ts = df.iloc[j][f'TimeStamp_{aid}']\n",
    "#             if pd.isna(next_ts):\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 next_ts = float(next_ts)\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#             diff = abs(next_ts - base_ts)\n",
    "#             if diff < 15000 and diff < min_diff:\n",
    "#                 min_diff = diff\n",
    "#                 closest_value = df.iloc[j][f'Value_{aid}']\n",
    "\n",
    "#         if closest_value is not None:\n",
    "#             base_values[f'Value_{aid}'] = closest_value\n",
    "#         else:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#     if valid:\n",
    "#         # ذخیره TimeStamp عددی\n",
    "#         base_values['BaseTimeStamp'] = base_ts\n",
    "#         # تبدیل به datetime و ذخیره در ستون جداگانه\n",
    "#         base_values['BaseDateTime'] = pd.to_datetime(base_ts, unit='s')\n",
    "#         final_rows.append(base_values)\n",
    "\n",
    "# # ساخت دیتافریم نهایی\n",
    "# df_final = pd.DataFrame(final_rows)\n",
    "\n",
    "# # ذخیره فایل نهایی\n",
    "# df_final.to_csv('matched_values_with_datetime.csv', index=False)\n",
    "\n",
    "# print(\"✅ فایل نهایی با ستون datetime قابل استفاده در تایم‌سریز ذخیره شد: matched_values_with_datetime.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # بارگذاری فایل خروجی قبلی\n",
    "# df = pd.read_csv('flattened_by_assetid.csv')\n",
    "\n",
    "# # لیست AssetIDها\n",
    "# asset_ids = [9362, 9363, 9364, 9365, 9366, 9367, 9371, 9372]\n",
    "\n",
    "# # لیست برای نگهداری ردیف‌های نهایی\n",
    "# final_rows = []\n",
    "\n",
    "# # تعداد ردیف‌ها\n",
    "# n = len(df)\n",
    "\n",
    "# # پیمایش ردیف‌ها\n",
    "# for i in range(n):\n",
    "#     row = df.iloc[i]\n",
    "#     base_values = {}\n",
    "#     valid = True\n",
    "\n",
    "#     for aid in asset_ids:\n",
    "#         base_ts = row[f'TimeStamp_{aid}']\n",
    "#         if pd.isna(base_ts):\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # تبدیل به عدد برای محاسبه اختلاف\n",
    "#         try:\n",
    "#             base_ts = float(base_ts)\n",
    "#         except:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#         # جستجوی نزدیک‌ترین TimeStamp در 5 ردیف بعدی\n",
    "#         min_diff = float('inf')\n",
    "#         closest_value = None\n",
    "#         matched_ts = None\n",
    "\n",
    "#         for j in range(i+1, min(i+6, n)):\n",
    "#             next_ts = df.iloc[j][f'TimeStamp_{aid}']\n",
    "#             if pd.isna(next_ts):\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 next_ts = float(next_ts)\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#             diff = abs(next_ts - base_ts)\n",
    "#             if diff < 3600 and diff < min_diff:\n",
    "#                 min_diff = diff\n",
    "#                 closest_value = df.iloc[j][f'Value_{aid}']\n",
    "#                 matched_ts = next_ts\n",
    "\n",
    "#         if closest_value is not None and matched_ts is not None:\n",
    "#             base_values[f'Value_{aid}'] = closest_value\n",
    "#             base_values[f'MatchedTimeStamp_{aid}'] = pd.to_datetime(matched_ts, unit='s')\n",
    "#         else:\n",
    "#             valid = False\n",
    "#             break\n",
    "\n",
    "#     if valid:\n",
    "#         base_values['BaseTimeStamp'] = base_ts\n",
    "#         base_values['BaseDateTime'] = pd.to_datetime(base_ts, unit='s')\n",
    "#         final_rows.append(base_values)\n",
    "\n",
    "# # ساخت دیتافریم نهایی\n",
    "# df_final = pd.DataFrame(final_rows)\n",
    "\n",
    "# # ذخیره فایل نهایی\n",
    "# df_final.to_csv('matched_values_with_timestamps.csv', index=False)\n",
    "\n",
    "# print(\"✅ فایل نهایی با مقادیر Value و TimeStampهای تطبیق‌یافته ذخیره شد: matched_values_with_timestamps.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # مرحله 1: خواندن فایل CSV\n",
    "# df = pd.read_csv('gen_brg_vib.csv')\n",
    "\n",
    "# # مرحله 2: استخراج AssetIDهای یکتا\n",
    "# unique_ids = df['AssetID'].unique().tolist()\n",
    "\n",
    "# # مرحله 3: ساخت دیتافریم خروجی\n",
    "# columns = ['TimeStamp'] + [f'AssetID_{uid}' for uid in unique_ids]\n",
    "# output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# # مرحله 4 تا 8: پردازش تکراری\n",
    "# while not df.empty and unique_ids:\n",
    "#     main_id = unique_ids[0]\n",
    "#     main_subset = df[df['AssetID'] == main_id]\n",
    "\n",
    "#     if main_subset.empty:\n",
    "#         # اگر هیچ ردیفی برای این AssetID نبود، حذفش کن و برو سراغ بعدی\n",
    "#         unique_ids.pop(0)\n",
    "#         continue\n",
    "\n",
    "#     # مرحله 5: گرفتن اولین ردیف\n",
    "#     main_row = main_subset.iloc[0]\n",
    "#     main_ts = main_row['TimeStamp']\n",
    "#     main_value = main_row['Value']\n",
    "#     used_indices = [main_row.name]\n",
    "\n",
    "#     # مرحله 6: پیدا کردن نزدیک‌ترین TimeStamp برای سایر AssetIDها\n",
    "#     row_data = {'TimeStamp': main_ts, f'AssetID_{main_id}': main_value}\n",
    "\n",
    "#     for other_id in unique_ids[1:]:\n",
    "#         subset = df[df['AssetID'] == other_id].copy()\n",
    "#         if subset.empty:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "#             continue\n",
    "\n",
    "#         subset['ts_diff'] = np.abs(subset['TimeStamp'] - main_ts)\n",
    "#         close_rows = subset[subset['ts_diff'] <= 1000]\n",
    "\n",
    "#         if not close_rows.empty:\n",
    "#             closest_row = close_rows.sort_values('ts_diff').iloc[0]\n",
    "#             row_data[f'AssetID_{other_id}'] = closest_row['Value']\n",
    "#             used_indices.append(closest_row.name)\n",
    "#         else:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "\n",
    "#     # مرحله 7: حذف ردیف‌های استفاده‌شده\n",
    "#     df.drop(index=used_indices, inplace=True)\n",
    "\n",
    "#     # مرحله 8: اضافه کردن به خروجی\n",
    "#     output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# # نمایش خروجی\n",
    "# print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # مرحله 1: خواندن فایل CSV\n",
    "# df = pd.read_csv('gen_brg_vib.csv')\n",
    "\n",
    "# # مرحله 2: استخراج AssetIDهای یکتا\n",
    "# unique_ids = df['AssetID'].unique().tolist()\n",
    "\n",
    "# # مرحله 3: ساخت دیتافریم خروجی با ستون‌های مورد نظر\n",
    "# columns = ['TimeStamp'] + [f'AssetID_{uid}' for uid in unique_ids]\n",
    "# output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# # مرحله 4 تا 8: پردازش تکراری تا خالی شدن دیتافریم اصلی\n",
    "# while not df.empty and unique_ids:\n",
    "#     main_id = unique_ids[0]\n",
    "#     main_subset = df[df['AssetID'] == main_id]\n",
    "\n",
    "#     if main_subset.empty:\n",
    "#         unique_ids.pop(0)\n",
    "#         continue\n",
    "\n",
    "#     # مرحله 5: گرفتن اولین ردیف از AssetID اصلی\n",
    "#     main_row = main_subset.iloc[0]\n",
    "#     main_ts = main_row['TimeStamp']\n",
    "#     main_value = main_row['Value']\n",
    "#     used_indices = [main_row.name]\n",
    "\n",
    "#     # مرحله 6: پیدا کردن نزدیک‌ترین TimeStamp برای سایر AssetIDها\n",
    "#     row_data = {'TimeStamp': main_ts, f'AssetID_{main_id}': main_value}\n",
    "\n",
    "#     for other_id in unique_ids[1:]:\n",
    "#         subset = df[df['AssetID'] == other_id].copy()\n",
    "#         if subset.empty:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "#             continue\n",
    "\n",
    "#         subset['ts_diff'] = np.abs(subset['TimeStamp'] - main_ts)\n",
    "#         close_rows = subset[subset['ts_diff'] <= 1000]\n",
    "\n",
    "#         if not close_rows.empty:\n",
    "#             closest_row = close_rows.sort_values('ts_diff').iloc[0]\n",
    "#             row_data[f'AssetID_{other_id}'] = closest_row['Value']\n",
    "#             used_indices.append(closest_row.name)\n",
    "#         else:\n",
    "#             row_data[f'AssetID_{other_id}'] = np.nan\n",
    "\n",
    "#     # مرحله 7: حذف ردیف‌های استفاده‌شده\n",
    "#     df.drop(index=used_indices, inplace=True)\n",
    "\n",
    "#     # مرحله 8: اضافه کردن ردیف جدید به خروجی\n",
    "#     output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# # ذخیره خروجی در فایل اکسل\n",
    "# output_df.to_excel('output.xlsx', index=False)\n",
    "\n",
    "# print(\"✅ پردازش کامل شد و خروجی در فایل output.xlsx ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pishva_r\\AppData\\Local\\Temp\\ipykernel_14816\\347181660.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ پردازش کامل شد، ستون date اضافه شد، و خروجی در فایل output.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# مرحله 1: خواندن فایل CSV\n",
    "df = pd.read_csv('dsas11_gen_brg_vib_9362_9367_9371_9372.csv')\n",
    "\n",
    "# مرحله 2: استخراج AssetIDهای یکتا\n",
    "unique_ids = df['AssetID'].unique().tolist()\n",
    "\n",
    "# مرحله 3: ساخت دیتافریم خروجی با ستون‌های مورد نظر\n",
    "columns = ['TimeStamp'] + [f'AssetID_{uid}' for uid in unique_ids]\n",
    "output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# مرحله 4 تا 8: پردازش تکراری تا خالی شدن دیتافریم اصلی\n",
    "while not df.empty and unique_ids:\n",
    "    main_id = unique_ids[0]\n",
    "    main_subset = df[df['AssetID'] == main_id]\n",
    "\n",
    "    if main_subset.empty:\n",
    "        unique_ids.pop(0)\n",
    "        continue\n",
    "\n",
    "    # مرحله 5: گرفتن اولین ردیف از AssetID اصلی\n",
    "    main_row = main_subset.iloc[0]\n",
    "    main_ts = main_row['TimeStamp']\n",
    "    main_value = main_row['Value']\n",
    "    used_indices = [main_row.name]\n",
    "\n",
    "    # مرحله 6: پیدا کردن نزدیک‌ترین TimeStamp برای سایر AssetIDها\n",
    "    row_data = {'TimeStamp': main_ts, f'AssetID_{main_id}': main_value}\n",
    "\n",
    "    for other_id in unique_ids[1:]:\n",
    "        subset = df[df['AssetID'] == other_id].copy()\n",
    "        if subset.empty:\n",
    "            row_data[f'AssetID_{other_id}'] = np.nan\n",
    "            continue\n",
    "\n",
    "        subset['ts_diff'] = np.abs(subset['TimeStamp'] - main_ts)\n",
    "        close_rows = subset[subset['ts_diff'] <= 1800]\n",
    "\n",
    "        if not close_rows.empty:\n",
    "            closest_row = close_rows.sort_values('ts_diff').iloc[0]\n",
    "            row_data[f'AssetID_{other_id}'] = closest_row['Value']\n",
    "            used_indices.append(closest_row.name)\n",
    "        else:\n",
    "            row_data[f'AssetID_{other_id}'] = np.nan\n",
    "\n",
    "    # مرحله 7: حذف ردیف‌های استفاده‌شده\n",
    "    df.drop(index=used_indices, inplace=True)\n",
    "\n",
    "    # مرحله 8: اضافه کردن ردیف جدید به خروجی\n",
    "    output_df = pd.concat([output_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "# مرحله نهایی: تبدیل TimeStamp به تاریخ و زمان و اضافه کردن ستون جدید\n",
    "output_df['date'] = pd.to_datetime(output_df['TimeStamp'], unit='s')\n",
    "output_df.drop(columns=['TimeStamp'], inplace=True)\n",
    "output_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "\n",
    "# ذخیره خروجی در فایل اکسل\n",
    "output_df.to_excel('output_gen_brg_vib_9362_9367_9371_9372.xlsx', index=False)\n",
    "\n",
    "print(\"✅ پردازش کامل شد، ستون date اضافه شد، و خروجی در فایل output.xlsx ذخیره شد.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
